{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc050c31-c53e-4240-8bf9-c9f2657e693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50945f09-40a3-4685-837d-76d4c2711915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bfb57-cc0a-4363-aaaf-37359ce80058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('/content/400xhighdensity.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c530ac-d149-4ec3-9632-6fc32b6195a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "!pip install sciPY\n",
    "import scipy\n",
    "!pip install matplotlib\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "!pip install Pillow\n",
    "!pip install tensorflow\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
    "#from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential  # Assuming TensorFlow 2.0+\n",
    "import keras\n",
    "!pip install keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "!pip install keras-preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "import PIL.Image\n",
    "from tensorflow.keras.preprocessing.image import load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5a392-befb-4c45-be4a-c27ccae0bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "!pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68396dd-f59e-4196-a543-ae3bf1699433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert into patches \n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_patches_224_folder(\n",
    "        img_dir: str,\n",
    "        out_root: str = \"patches_224\",\n",
    "        patch_size: int = 224,\n",
    "        stride: int = 50,\n",
    "        exts=(\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Split all images in a folder into 224×224 overlapping patches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_dir : str\n",
    "        Input directory with images.\n",
    "    out_root : str\n",
    "        Output root directory for patches.\n",
    "    patch_size : int\n",
    "        Size of square patches (default 224).\n",
    "    stride : int\n",
    "        Step size for sliding window (default 50).\n",
    "    exts : tuple\n",
    "        Allowed file extensions.\n",
    "    \"\"\"\n",
    "    img_dir = Path(img_dir)\n",
    "    out_root = Path(out_root)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Loop through all images in folder\n",
    "    for img_path in img_dir.glob(\"*\"):\n",
    "        if img_path.suffix.lower() not in exts:\n",
    "            continue  # skip non-image files\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Skipping unreadable file: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        H, W = img.shape[:2]\n",
    "        stem = img_path.stem\n",
    "\n",
    "        # Create output subfolder for each image\n",
    "        out_sub = out_root / stem\n",
    "        out_sub.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        pid = 0\n",
    "        for y in range(0, H - patch_size + 1, stride):\n",
    "            for x in range(0, W - patch_size + 1, stride):\n",
    "                patch = img[y:y+patch_size, x:x+patch_size]\n",
    "                cv2.imwrite(str(out_sub / f\"{stem}_p_{pid:04d}.png\"), patch)\n",
    "                pid += 1\n",
    "\n",
    "        print(f\"Saved {pid} patches for {img_path.name} → {out_sub}\")\n",
    "\n",
    "\n",
    "# ---------------- Example ----------------\n",
    "# Convert all images in a folder\n",
    "extract_patches_224_folder(\n",
    "    img_dir=\"/content/input_images\",   # folder with your images\n",
    "    out_root=\"patches_224\",           # root folder for patches\n",
    "    patch_size=224,\n",
    "    stride=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8a0f5-3367-4033-b44b-65a93e7e0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deconvolution Macenko method Remove stain\n",
    "import staintools\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "def macenko_stain_normalization(\n",
    "        input_dir: str,\n",
    "        output_dir: str = \"stain_normalized\",\n",
    "        template_path: str = None,\n",
    "        exts=(\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply Macenko stain normalization to all images in a folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dir : str\n",
    "        Folder containing input histopathology images.\n",
    "    output_dir : str\n",
    "        Folder to save stain-normalized images.\n",
    "    template_path : str\n",
    "        Path to a template/reference image for Macenko normalization.\n",
    "    exts : tuple\n",
    "        Allowed image file extensions.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load template image\n",
    "    if template_path is None:\n",
    "        raise ValueError(\"You must provide a template image for Macenko normalization!\")\n",
    "\n",
    "    template = staintools.read_image(template_path)\n",
    "    template = staintools.LuminosityStandardizer.standardize(template)\n",
    "\n",
    "    normalizer = staintools.StainNormalizer(method='macenko')\n",
    "    normalizer.fit(template)\n",
    "\n",
    "    for img_path in input_dir.glob(\"*\"):\n",
    "        if img_path.suffix.lower() not in exts:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = staintools.read_image(str(img_path))\n",
    "            img = staintools.LuminosityStandardizer.standardize(img)\n",
    "            norm_img = normalizer.transform(img)\n",
    "\n",
    "            # Save normalized image\n",
    "            out_path = output_dir / img_path.name\n",
    "            cv2.imwrite(str(out_path), cv2.cvtColor(norm_img, cv2.COLOR_RGB2BGR))\n",
    "            print(f\"Saved: {out_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {img_path.name}: {e}\")\n",
    "\n",
    "\n",
    "# ---------------- Example ----------------\n",
    "macenko_stain_normalization(\n",
    "    input_dir=\"/content/histo_images\",              # folder of histopathology images\n",
    "    output_dir=\"stain_normalized\",                  # save normalized images here\n",
    "    template_path=\"/content/template_image.png\"     # reference image for normalization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c12641-74a2-4450-aa71-c177d6c9d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split \n",
    "#count number of images and classes Benign=0 maligant=1\n",
    "ROOT_DIR=\"/content/\"\n",
    "number_of_images={}\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "       number_of_images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))\n",
    "       number_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ef667-3172-4525-a270-bd1570e0291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in each class\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))\n",
    "\n",
    "# Split the dataset: 70% training, 15% testing, and 15% validation\n",
    "if not os.path.exists(\"./train400h\"):\n",
    "    os.mkdir(\"./train400h\")\n",
    "    os.mkdir(\"./test400h\")\n",
    "    os.mkdir(\"./validation400h\")\n",
    "\n",
    "    for dir in os.listdir(ROOT_DIR):\n",
    "        os.makedirs(\"./train400h/\" + dir)\n",
    "        os.makedirs(\"./test400h/\" + dir)\n",
    "        os.makedirs(\"./validation400h/\" + dir)\n",
    "        # Calculate the number of images for each split\n",
    "        train_size = math.floor(0.7 * number_of_images[dir])\n",
    "        test_size = math.floor(0.15 * number_of_images[dir])\n",
    "        validation_size = number_of_images[dir] - train_size - test_size\n",
    "\n",
    "        # Get a random sample of images for each split\n",
    "        all_images = os.listdir(os.path.join(ROOT_DIR, dir))\n",
    "        train_images = np.random.choice(all_images, size=train_size, replace=False)\n",
    "        remaining_images = list(set(all_images) - set(train_images))\n",
    "        test_images = np.random.choice(remaining_images, size=test_size, replace=False)\n",
    "        validation_images = list(set(remaining_images) - set(test_images))\n",
    "\n",
    "        # Move images to the appropriate folders\n",
    "        for img in train_images:\n",
    "            source_path = os.path.join(ROOT_DIR, dir, img)\n",
    "            destination_path = os.path.join(\"./train400h\", dir, img)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "            os.remove(source_path)\n",
    "\n",
    "        for img in test_images:\n",
    "            source_path = os.path.join(ROOT_DIR, dir, img)\n",
    "            destination_path = os.path.join(\"./test400h\", dir, img)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "            os.remove(source_path)\n",
    "\n",
    "        for img in validation_images:\n",
    "            source_path = os.path.join(ROOT_DIR, dir, img)\n",
    "            destination_path = os.path.join(\"./validation400h\", dir, img)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "            os.remove(source_path)\n",
    "else:\n",
    "    print(\"The folders already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d2b46-438e-42ad-add4-ec38e6d1165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in the validation folder\n",
    "number_of_images_val = {}\n",
    "for dir in os.listdir(\"./validation400h\"):\n",
    "    number_of_images_val[dir] = len(os.listdir(os.path.join(\"./validation400h\", dir)))\n",
    "\n",
    "number_of_images_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aebc00-1d8b-4503-90aa-4057d2df1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in the training folder\n",
    "number_of_images_train = {}\n",
    "for dir in os.listdir(\"./train400h\"):\n",
    "    number_of_images_train[dir] = len(os.listdir(os.path.join(\"./train400h\", dir)))\n",
    "\n",
    "number_of_images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1718284-8e6e-4be8-a570-7158a970f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in the test folder\n",
    "number_of_images_test = {}\n",
    "for dir in os.listdir(\"./test400h\"):\n",
    "    number_of_images_test[dir] = len(os.listdir(os.path.join(\"./test400h\", dir)))\n",
    "\n",
    "number_of_images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cabbc-6ac0-4b6c-9957-505833060a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Assuming you're using TensorFlow with Keras\n",
    "\n",
    "# Define your data directories\n",
    "train_path = \"train400h\"\n",
    "validation_path = \"validation400h\"  # Clear name for validation set\n",
    "#test_path = \"test400\"               # Separate directory for testing\n",
    "\n",
    "# Set up data generators for training, validation, and testing\n",
    "\n",
    "def preprocessing_images(path, target_size=(224, 224), batch_size=32, class_mode='categorical'):\n",
    "  \"\"\"\n",
    "  Preprocesses images using ImageDataGenerator and returns a data generator.\n",
    "\n",
    "  Args:\n",
    "      path: Path to the directory containing images.\n",
    "      target_size: Target size (width, height) to resize the images.\n",
    "      batch_size: Batch size for training the model.\n",
    "      class_mode: Mode for classifying images ('binary' for 2 classes,\n",
    "                   'categorical' for more than 2 classes).\n",
    "\n",
    "  Returns:\n",
    "      A Keras ImageDataGenerator object representing the preprocessed dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  image_data = ImageDataGenerator(\n",
    "      rescale=1/255,  # Normalize pixel values to [0, 1]\n",
    "      zoom_range=0.1,  # Randomly zoom images by up to 10%\n",
    "      shear_range=0.2,  # Randomly shear images by up to 20 degrees\n",
    "      rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
    "      horizontal_flip=True,  # Randomly flip images horizontally\n",
    "      vertical_flip=True   # Randomly flip images vertically\n",
    "  )\n",
    "\n",
    "  # Use flow_from_directory to create data generators\n",
    "  image_generator = image_data.flow_from_directory(\n",
    "      directory=path,\n",
    "      target_size=target_size,\n",
    "      batch_size=batch_size,\n",
    "      class_mode=class_mode\n",
    "  )\n",
    "\n",
    "  return image_generator\n",
    "\n",
    "\n",
    "\n",
    "# Create training, validation, and test data generators\n",
    "train_data = preprocessing_images(train_path)\n",
    "val_data = preprocessing_images(validation_path)\n",
    "#test_data = preprocessing_images(test_path)  # Create a separate generator for testing\n",
    "\n",
    "# Build your image classification model (code not provided)\n",
    "\n",
    "# Train your model using train_data and val_data for validation\n",
    "\n",
    "# Evaluate your model's performance on the test set using test_data\n",
    "\n",
    "# (Code for building, training, and evaluating the model is not provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9b698-4d47-4618-8023-5dcdb50dcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your data directories\n",
    "train_path = \"train400h\"\n",
    "#test_path = \"test400m\"\n",
    "\n",
    "# Set up data generators for training and validation\n",
    "def preprocessingImages(path):\n",
    "    # Apply data augmentation (rotation and flip)\n",
    "    image_data = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        zoom_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=20,  # Rotate images randomly up to 20 degrees\n",
    "        horizontal_flip=True,  # Flip images horizontally\n",
    "        vertical_flip=True  # Flip images vertically\n",
    "    )\n",
    "    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "    return image\n",
    "\n",
    "train_data = preprocessingImages(train_path)\n",
    "#test_data = preprocessingImages(test_path)\n",
    "val_data = preprocessingImages(validation_path)  # Create validation data similarly to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79410482-4d08-4b98-b68b-81203b879e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your data directories\n",
    "train_path = \"train400h\"\n",
    "#test_path = \"test400\"\n",
    "\n",
    "# Set up data generators for training and validation\n",
    "def preprocessingImages(path):\n",
    "    # Apply data augmentation (rotation and flip)\n",
    "    image_data = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        zoom_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=20,  # Rotate images randomly up to 20 degrees\n",
    "        horizontal_flip=True,  # Flip images horizontally\n",
    "        vertical_flip=True  # Flip images vertically\n",
    "    )\n",
    "    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), batch_size=40, class_mode='categorical')\n",
    "    return image\n",
    "\n",
    "train_data = preprocessingImages(train_path)\n",
    "val_data = preprocessingImages(validation_path)  # Create validation data similarly to training data\n",
    "\n",
    "print(\"Data generators for training and validation (with data augmentation) created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db6107-57e2-4d9f-9799-d67557b89585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already imported necessary libraries (e.g., ImageDataGenerator, matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate augmented images\n",
    "augmented_images = next(train_data)  # Get a batch of augmented images\n",
    "\n",
    "# Display a few augmented images\n",
    "fig, axs = plt.subplots(4, 4, figsize=(6, 6))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < len(augmented_images[0]):  # Check if index is within bounds\n",
    "        ax.imshow(augmented_images[0][i])\n",
    "        ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "num_batches = len(train_data)  # Number of batches\n",
    "batch_size = 32  # Your specified batch size\n",
    "total_augmented_images = num_batches * batch_size\n",
    "print(f\"Total augmented images: {total_augmented_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20d7f0-aee1-4c60-9d7d-b00db1f65189",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
    "#from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential  # Assuming TensorFlow 2.0+\n",
    "import keras\n",
    "!pip install keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "!pip install keras-preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l1, l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d2ca0-b209-4086-9479-436c722044d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DLA1\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define CNN model with 6 convolutional layers\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Conv layer\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Conv layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3rd Conv layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Conv layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 5th Conv layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 6th Conv layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout to reduce overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Flatten + Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation='softmax'))  # 2 classes: benign vs malignant\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf6cbe-8921-417e-9558-8865a7cf8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DLA2\n",
    "\n",
    "# Import necessary libraries from TensorFlow's Keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "import PIL.Image\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "#model.add(Conv2D(filters=16, kernel_size=(3, 3),input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=36, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=124, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Flatten())\n",
    "model.add (Dense(units=64,activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add (Dense(units=2,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d941aba-26c7-4355-a997-38f8611348e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DLA3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.models import Model,load_model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "# Import necessary libraries from TensorFlow's Keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9019f0c-276a-4a06-98c7-46846a3de6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNet(input_shape=(224,224,3),include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbcf67e-e9f3-4e71-9b7f-5f6c0706154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Flatten()(base_model.output)\n",
    "X=Dense(units=2,activation ='softmax')(X)\n",
    "model=Model(base_model.input,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4334f21-76b5-48d3-ab4b-9f3c88760023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr_warmup_epochs = 25, lr_min = 1e-5, lr_max = 5e-5,  lr_exp_decay = 0.8):\n",
    "    lr_start = lr_min\n",
    "    if epoch < lr_warmup_epochs:\n",
    "        lr = (lr_max - lr_start) / lr_warmup_epochs * epoch + lr_start\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_warmup_epochs) + lr_min\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c23bc0-8003-422a-9188-36daf46f1a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69b40f-c008-4832-90be-c0928e40c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate schedules(final)\n",
    "def lr_schedule(epoch, lr_warmup_epochs=25, lr_min=1e-5, lr_max=5e-5, lr_exp_decay=0.8):\n",
    "  \"\"\"\n",
    "  Defines a learning rate schedule with warmup and exponential decay.\n",
    "\n",
    "  Args:\n",
    "    epoch (int): Current training epoch.\n",
    "    lr_warmup_epochs (int, optional): Number of epochs for warmup. Defaults to 25.\n",
    "    lr_min (float, optional): Minimum learning rate. Defaults to 1e-5.\n",
    "    lr_max (float, optional): Maximum learning rate. Defaults to 5e-5.\n",
    "    lr_exp_decay (float, optional): Learning rate exponential decay factor. Defaults to 0.8.\n",
    "\n",
    "  Returns:\n",
    "    float: The learning rate for the current epoch.\n",
    "  \"\"\"\n",
    "  lr_start = lr_min\n",
    "  if epoch < lr_warmup_epochs:\n",
    "    lr = (lr_max - lr_start) / lr_warmup_epochs * epoch + lr_start\n",
    "  else:\n",
    "    lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_warmup_epochs) + lr_min\n",
    "  return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "  \"\"\"\n",
    "  Defines a learning rate schedule with step-wise decay.\n",
    "\n",
    "  Args:\n",
    "    epoch (int): Current training epoch.\n",
    "\n",
    "  Returns:\n",
    "    float: The learning rate for the current epoch.\n",
    "  \"\"\"\n",
    "  decay_factor = 0.8  # Adjust this factor for desired decay rate\n",
    "  initial_learning_rate = 0.01\n",
    "  lrate = initial_learning_rate * (1 / (1 + decay_factor * epoch))\n",
    "  return lrate\n",
    "\n",
    "# Compile the model (assuming you have defined it and set the optimizer)\n",
    "model.compile(optimizer='RMSprop', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "# Choose the desired learning rate schedule\n",
    "learning_rate_scheduler = LearningRateScheduler(lr_schedule)  # Uncomment for exponential decay with warmup\n",
    "# learning_rate_scheduler = LearningRateScheduler(step_decay)  # Uncomment for step-wise decay (optional)\n",
    "\n",
    "# If using a learning rate scheduler, add it to the model callbacks\n",
    "if learning_rate_scheduler:\n",
    "  callbacks = [learning_rate_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f95506-0b68-4f6f-8824-fb34fd4778a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "  \"\"\"\n",
    "  Defines a step decay learning rate schedule.\n",
    "\n",
    "  Args:\n",
    "      epoch (int): Current training epoch.\n",
    "\n",
    "  Returns:\n",
    "      float: The learning rate for the current epoch.\n",
    "  \"\"\"\n",
    "  decay_factor = 0.8  # Adjust this factor for desired decay rate\n",
    "  initial_learning_rate = 0.01\n",
    "  lrate = initial_learning_rate * (1 / (1 + decay_factor * epoch))\n",
    "  return lrate  # This line should only return the learning rate\n",
    "\n",
    "# Compile the model (assuming you have defined it and set the optimizer)\n",
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "# Create the LearningRateScheduler object with the defined function\n",
    "learning_rate_scheduler = LearningRateScheduler(step_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a119ba-d5be-475f-8028-f4778171b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Define the model checkpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Define your learning rate scheduler callback (already assumed to be created)\n",
    "# learning_rate_scheduler = ...\n",
    "\n",
    "# Fit the model with learning rate scheduler and model checkpoint\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=5,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10,\n",
    "    callbacks=[learning_rate_scheduler, checkpoint]  # Adding both scheduler and checkpoint\n",
    ")\n",
    "\n",
    "# Plot Training & Validation Accuracy Graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Training & Validation Loss Graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Access learning rates (assuming it's logged in history as 'lr') and plot Learning Rate vs Epoch\n",
    "if 'lr' in history.history:\n",
    "    learning_rates = history.history['lr']\n",
    "    epochs = range(len(learning_rates))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, learning_rates)\n",
    "    plt.title('Learning Rate vs. Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a7123-e20c-441b-a2aa-bea27019906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the best saved model\n",
    "best_model = load_model('best_model.keras')\n",
    "\n",
    "# Test data directory (replace with your actual path)\n",
    "test_data_dir = 'test400h'\n",
    "\n",
    "# Image dimensions (replace with your image dimensions used during training)\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "\n",
    "# Preprocess test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generator for test images\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Assuming multi-class classification (modify as per your case)\n",
    "    shuffle=False  # Important to set shuffle to False for correct prediction alignment\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = best_model.predict(test_generator, steps=test_generator.samples // batch_size + 1)\n",
    "\n",
    "# Get predicted class indices (argmax) for multi-class or binary\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Ground truth labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Class labels (modify this if you have more than two classes)\n",
    "class_labels = list(test_generator.class_indices.keys())  # Get class labels from generator\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Test Accuracy\n",
    "test_accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "print(f\"\\nPrecision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# AUC-ROC Curve (for binary or multi-class)\n",
    "# If binary classification, calculate AUC directly\n",
    "if len(class_labels) == 2:\n",
    "    # For binary classification, roc_auc_score expects the probabilities for the positive class\n",
    "    auc_score = roc_auc_score(true_classes, predictions[:, 1])\n",
    "    print(f\"AUC: {auc_score:.2f}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(true_classes, predictions[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # For multi-class classification, use one-vs-rest strategy\n",
    "    auc_score = roc_auc_score(true_classes, predictions, multi_class='ovr')\n",
    "    print(f\"AUC: {auc_score:.2f}\")\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    for i, label in enumerate(class_labels):\n",
    "        fpr, tpr, _ = roc_curve(true_classes == i, predictions[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc_score(true_classes == i, predictions[:, i]):.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cc246-1a25-47eb-ac56-b4d31c176851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the best saved model\n",
    "best_model = load_model('best_model.keras')\n",
    "\n",
    "# Test data directory (replace with your actual path)\n",
    "test_data_dir = 'test400m'\n",
    "\n",
    "# Image dimensions (replace with your image dimensions used during training)\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "\n",
    "# Preprocess test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generator for test images\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Assuming binary classification\n",
    "    shuffle=False  # Important to set shuffle to False for correct prediction alignment\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = best_model.predict(test_generator, steps=test_generator.samples // batch_size + 1)\n",
    "\n",
    "# Get predicted class indices (argmax) for binary classification\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Ground truth labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Class labels\n",
    "class_labels = list(test_generator.class_indices.keys())  # Get class labels from generator\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plotting the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Test Accuracy\n",
    "test_accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "print(f\"\\nPrecision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# AUC-ROC Curve (for binary or multi-class)\n",
    "if len(class_labels) == 2:\n",
    "    # For binary classification\n",
    "    auc_score = roc_auc_score(true_classes, predictions[:, 1])\n",
    "    print(f\"AUC: {auc_score:.2f}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(true_classes, predictions[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    # For multi-class classification\n",
    "    auc_score = roc_auc_score(true_classes, predictions, multi_class='ovr')\n",
    "    print(f\"AUC: {auc_score:.2f}\")\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    for i, label in enumerate(class_labels):\n",
    "        fpr, tpr, _ = roc_curve(true_classes == i, predictions[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc_score(true_classes == i, predictions[:, i]):.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7c0ba-7ecf-4569-bf3b-2f63bb7bc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
